# ğŸ“š DocsGPT â€” Chat with Your Own Documents

**DocsGPT** My project is called DocsGPT â€“ Chat with Your Documents. Itâ€™s an intelligent document assistant where users can upload PDF files and ask questions in natural language, and the system provides accurate, context-based answers.

The main motivation behind this project was data security and integrity. Many companies donâ€™t want to upload their confidential product documents or company data to third-party AI tools like ChatGPT. So I designed a solution where the processing happens locally with FAISS as the vector database and Googleâ€™s Generative AI APIs integrated via LangChain. This way, the companyâ€™s documents stay private and are never exposed externally.

Hereâ€™s how the system works technically:

* PDF Handling â€“ I use PyPDF2 to extract raw text from uploaded documents.

* Text Chunking â€“ The text is split into smaller overlapping chunks using LangChainâ€™s CharacterTextSplitter to maintain context.

* Embeddings & Vector Store â€“ Each chunk is converted into embeddings using Google Generative AI embeddings and stored in FAISS, which allows fast and secure similarity search.

* Question Answering â€“ When a user asks a question, relevant chunks are retrieved from FAISS and passed into Gemini 1.5 Flash via LangChainâ€™s QA chain, with a prompt that ensures only context-based answers are generated.

* Frontend & UI â€“ I used Streamlit for the user interface, where I added styled Q&A cards, animations, and a responsive layout for a better user experience.

From a business perspective, this tool can be extremely useful for onboarding freshers or beginners in a company. Instead of asking seniors or manually searching long documents, they can simply upload training manuals, product documents, or internal guides, and get instant, accurate answers while ensuring the data never leaves the companyâ€™s environment.

In short, my project combines AI + Security + Usability â€” making it practical for real enterprise use cases while also demonstrating my skills in Python, Streamlit, LangChain, embeddings, FAISS, and Generative AI APIs.

---

## ğŸš€ Features

- ğŸ“‚ **Upload multiple PDFs** and extract their text for querying.
- ğŸ¨ **Modern UI** with a welcome message, styled header, and responsive design.
- â³ **Thinking animation** during query processing for a smooth experience.
- ğŸ“ **Sidebar with PDF upload tips**, which disappear after processing.
- âš¡ **Efficient vector search** using **FAISS** for fast and accurate answers.

---

## ğŸ› ï¸ Technologies Used

- **Python** â€” Core backend logic and processing.
- **Streamlit** â€” Interactive web application framework.
- **Google Generative AI** â€” Embeddings & language model capabilities.
- **LangChain** â€” Conversational AI chains and vector stores.
- **FAISS** â€” Efficient similarity search and vector storage.
- **PyPDF2** â€” Extract text from PDF files.
- **python-dotenv** â€” Manage environment variables securely.

---

## ğŸ“¦ Python Modules Used

- `os` â€” Access environment variables.
- `streamlit` â€” Build the UI.
- `google.generativeai` â€” Interact with Google AI models.
- `langchain_google_genai` â€” LangChain integrations for Google Generative AI.
- `dotenv` â€” Load environment variables from `.env`.
- `PyPDF2` â€” Read and extract PDF text.
- `langchain.vectorstores` â€” Create/manage FAISS vector stores.
- `langchain.text_splitter` â€” Split text into chunks.
- `langchain.chains.question_answering` â€” Load the Q&A chain.
- `langchain.prompts` â€” Create AI model prompts.

---

## ğŸ“‚ Project Structure
```
docsgpt/
â”œâ”€â”€ app.py # Main Streamlit application
â”œâ”€â”€ htmlTemplates.py # HTML & CSS templates for custom styling
â”œâ”€â”€ .env # Environment variables (not tracked in Git)
â”œâ”€â”€ requirements.txt # List of Python dependencies
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ faiss_index/ # Generated FAISS vector store for embeddings
```
